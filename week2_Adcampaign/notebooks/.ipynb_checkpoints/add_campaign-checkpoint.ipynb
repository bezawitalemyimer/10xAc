{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a59340",
   "metadata": {},
   "source": [
    "# A/B Hypothesis Testing:Ad campaign performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236c1d5",
   "metadata": {},
   "source": [
    "The main objective of this project is to test if the ads that the advertising company runs resulted in a significant lift in brand awareness. \n",
    "This is a test run and the main objective is to validate the hypothesis algorithm you built. SmartAd ran this campaign from 3-10 July 2020.\n",
    "By using classical A/B testing and machine learning,smartAds plan to result insgnificant lift to the campany."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe42a0f",
   "metadata": {},
   "source": [
    "#Data exploration and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479b1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm \n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing  \n",
    "from sklearn.preprocessing import scale \n",
    "from scipy.stats import spearmanr #\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score #\n",
    "from sklearn.metrics import log_loss #\n",
    "from sklearn import metrics\n",
    "from matplotlib import rcParams #\n",
    "from matplotlib.pyplot import pie, axis, show\n",
    "from scipy.stats import norm  #\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a434d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec706623",
   "metadata": {},
   "source": [
    "A/B Hypothesis Testing: Ad campaign performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601251f",
   "metadata": {},
   "source": [
    "BIO Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0371e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading the data \n",
    "data = pd.read_csv(\"/Users/bez/desktop/10xAc/week2_Adcampaign/data/AdsmartABdata.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36312db",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#data set info \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30684a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimension of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeae5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#users who answered yes \n",
    "data[(data.yes==1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947558c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#users who answered no\n",
    "data[(data.no==1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d864114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#users who neither answered \"yes\" nor \"no\"\n",
    "data[(data.yes == 0)&(data.no == 0)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b270b75",
   "metadata": {},
   "source": [
    "* Out of the 8077 users 6834 chose not to respond to the survey,need to work with a valid response *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning and filtering data sets with those who answered\n",
    "answered =data[(data.yes == 1)|(data.no == 1)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping \n",
    "answered.drop('index', axis=1, inplace=True)\n",
    "answered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c83322",
   "metadata": {},
   "source": [
    "data has 9 features with unique values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique values of each column\n",
    "answered.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot(variable):\n",
    "    sns.countplot(x=variable, data=answered)\n",
    "    \n",
    "def bar_plot(variable):\n",
    "    sns.barplot(y=variable, x='yes', data=answered, orient='h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = answered[\"yes\"].groupby(answered.experiment).sum()\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title(\"experiment group count pie chart\")\n",
    "axis('equal');\n",
    "pie(sums, labels=sums.index);\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637e66f",
   "metadata": {},
   "source": [
    "the above pie chart shows more users in the exposed group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes \n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.barplot(data=data, x='experiment', y='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91b991",
   "metadata": {},
   "source": [
    "*Date*plot showing more users answered on 2020-07-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot value date \n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title(\"date count plot\")\n",
    "count_plot( \"date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdb313",
   "metadata": {},
   "source": [
    "*Hour*plot showing more users answered on 15:00 o'clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c70556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title(\"hour count plot\")\n",
    "count_plot( \"hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82d629",
   "metadata": {},
   "source": [
    "Chrome Mobile browser to be the most used browser among the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130626c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot value Hour\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.title(\"browser count plot\")\n",
    "count_plot(\"browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f713a73",
   "metadata": {},
   "source": [
    " plot showing most of users are using a generic smartphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotate x-axis labels 90 degree so we can \n",
    "plt.figure(figsize=(25,10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"device_make count plot\")\n",
    "count_plot(\"device_make\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7c9bf",
   "metadata": {},
   "source": [
    "The bar plots below show the relationships between the features\n",
    "and the responses to the advertisement and how is the answers are related to each feature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb391a00",
   "metadata": {},
   "source": [
    "shows the portion of users who said \"yes\" per browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"browser vs yes count\")\n",
    "bar_plot('browser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b84049",
   "metadata": {},
   "source": [
    "plot shows the portion of users who said \"yes\" per shows Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"date vs yes count\")\n",
    "bar_plot('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96972dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot shows the portion of users who said \"yes\" per hour. It looks users responding at 23:00 o'clock,\n",
    "    with any number said \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1772b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"hour vs yes count\")\n",
    "bar_plot('hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20956bf",
   "metadata": {},
   "source": [
    "plot shows that more users in the exposed group said yes than in control group.\n",
    "To prove this scientificaly we need to do A/B testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c500cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"experiment vs yes count\")\n",
    "bar_plot('experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef7b925",
   "metadata": {},
   "source": [
    "## Task 1.2 : Classic and sequential A/B testing analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23d679",
   "metadata": {},
   "source": [
    "#### classical A/B testing by calculating p-vale using statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbaa7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset of users with id and group only\n",
    "users = pd.DataFrame(data = answered[[\"auction_id\", \"experiment\"]])\n",
    "#add a column for the response\n",
    "users[\"converted\"] = answered.yes\n",
    "users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc30ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the control and exposed groups\n",
    "exposed = users[users.experiment == 'exposed']\n",
    "control = users[users.experiment == 'control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fccdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table to get the sum of converted users in each group\n",
    "summary = users.pivot_table(values='converted', index='experiment', aggfunc=np.sum)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional columns to the pivot table\n",
    "summary['total'] = users.pivot_table(values='converted', index='experiment', aggfunc=lambda x: len(x))\n",
    "summary['rate'] = users.pivot_table(values='converted', index='experiment')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18453f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_converted = summary['converted'][0]\n",
    "control_total = summary['total'][0]\n",
    "control_rate = summary['rate'][0]\n",
    "\n",
    "exposed_converted = summary['converted'][1]\n",
    "exposed_total = summary['total'][1]\n",
    "exposed_rate = summary['rate'][1]\n",
    "\n",
    "rate_difference = exposed_rate-control_rate\n",
    "rate_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "x = np.linspace(summary.iloc[0,0]-49, summary.iloc[0,0]+50, 100)\n",
    "y = scs.binom(control_total, control_rate).pmf(x)\n",
    "ax.bar(x, y, alpha=0.5)\n",
    "ax.axvline(x=exposed_rate*580 , c='green', alpha=0.75, linestyle='--')\n",
    "#ax.axvline(x=exposed_rate*A_total, c='blue', alpha=0.75, linestyle='--')\n",
    "plt.xlabel('converted')\n",
    "plt.ylabel('probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "xC = np.linspace(control_converted-49, control_converted+50, 100)\n",
    "yC = scs.binom(control_total, control_rate).pmf(xC)\n",
    "ax.bar(xC, yC, label = \"Control\",alpha=0.5)\n",
    "\n",
    "xE = np.linspace(exposed_converted-49, exposed_converted+50, 100)\n",
    "yE = scs.binom(exposed_total, exposed_rate).pmf(xE)\n",
    "ax.bar(xE, yE, label = \"Exposed\",alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('converted')\n",
    "plt.ylabel('probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99129273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_C = np.sqrt(ctrl_cr * (1-ctrl_cr)) / np.sqrt(ctrl_total)\n",
    "std_E = np.sqrt(exposed_rate * (1-exposed_rate)) / np.sqrt(exposed_total)\n",
    "\n",
    "# plot the null and alternative hypothesis\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "x = np.linspace(.35, .6, 1000)\n",
    "\n",
    "yC = scs.norm(ctrl_cr, std_C).pdf(x)\n",
    "ax.plot(x, yC,label = \"Control\")\n",
    "ax.axvline(x=ctrl_cr, c='red', alpha=0.5, linestyle='--')\n",
    "\n",
    "yE = scs.norm(exposed_rate, std_E).pdf(x)\n",
    "ax.plot(x, yE,label = \"Exposed\")\n",
    "ax.axvline(x=exposed_rate, c='blue', alpha=0.5, linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Converted rate')\n",
    "plt.ylabel('probablity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z_score = (rate_difference) / np.sqrt(std_C**2 + std_E**2)\n",
    "p = norm(rate_difference, np.sqrt(std_C**2 + std_E**2))\n",
    "\n",
    "x = np.linspace(-0.15, 0.15, 1000)\n",
    "y = p.pdf(x)\n",
    "area_under_curve = p.sf(0)\n",
    "plt.plot(x, y, label=\"PDF\")\n",
    "plt.fill_between(x, 0, y, where=x>0, label=\"Prob(exp>ctrl)\", alpha=0.3)\n",
    "plt.annotate(f\"Area={area_under_curve:0.3f}\", (0.02, 5))\n",
    "plt.legend()\n",
    "plt.xlabel(\"Difference in conversion rate\"); plt.ylabel(\"Prob\");\n",
    "\n",
    "print(f\"zscore is {z_score:0.3f}, with p-value {norm().sf(z_score):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_ab_test(a_c, num_a, b_c, num_b):\n",
    "    a_cr = a_c / num_a\n",
    "    b_cr = b_c / num_b\n",
    "    std_a = np.sqrt(a_cr * (1 - a_cr) / num_a)\n",
    "    std_b = np.sqrt(b_cr * (1 - b_cr) / num_b)\n",
    "    z_score = (b_cr - a_cr) / np.sqrt(std_a**2 + std_b**2)\n",
    "    return norm.cdf(z_score)\n",
    "\n",
    "print(get_confidence_ab_test(control_converted, control_total, exposed_converted, exposed_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(a_c, num_a, b_c, num_b):\n",
    "    a_cr = a_c / num_a\n",
    "    b_cr = b_c / num_b\n",
    "    std_a = np.sqrt(a_cr * (1 - a_cr) / num_a)\n",
    "    std_b = np.sqrt(b_cr * (1 - b_cr) / num_b)\n",
    "    z_score = (b_cr - a_cr) / np.sqrt(std_a**2 + std_b**2)\n",
    "    return norm.sf(z_score)\n",
    "\n",
    "print(get_p_value(control_converted, control_total, exposed_converted, exposed_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "rates_a = norm(control_rate, std_C).rvs(n)\n",
    "rates_b = norm(exposed_rate, std_E).rvs(n)\n",
    "b_better = (rates_b > rates_a).sum() /n\n",
    "print(\"exposed is better than control {b_better * 100:0.1f}% of the time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e994c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dist = np.zeros(control_total)\n",
    "a_dist[:control_converted] = 1\n",
    "b_dist = np.zeros(exposed_total)\n",
    "b_dist[:exposed_converted] = 1\n",
    "zscore, prob = scs.ttest_ind(a_dist, b_dist, equal_var=True)\n",
    "print(f\"Zscore is {zscore:0.2f}, p-value is {prob:0.3f} (two tailed), {prob/2:0.3f} (one tailed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.stats.ztest(b_dist,a_dist,alternative=\"larger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dfcb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a code to calculate sample size (borrowed from github)\n",
    "def min_sample_size(control_rate, rate_difference, power=0.8, sig_level=0.05):\n",
    "    \"\"\"Returns the minimum sample size to set up a split test\n",
    "    Arguments:\n",
    "        control_rate (float): probability of success for control, sometimes\n",
    "        referred to as baseline conversion rate\n",
    "        rate_difference (float): minimum change in measurement between control\n",
    "        group and test group if alternative hypothesis is true, sometimes\n",
    "        referred to as minimum detectable effect\n",
    "        power (float): probability of rejecting the null hypothesis when the\n",
    "        null hypothesis is false, typically 0.8\n",
    "        sig_level (float): significance level often denoted as alpha,\n",
    "        typically 0.05\n",
    "    Returns:\n",
    "        min_N: minimum sample size (float)\n",
    "    References:\n",
    "        Stanford lecture on sample sizes\n",
    "        http://statweb.stanford.edu/~susan/courses/s141/hopower.pdf\n",
    "    \"\"\"\n",
    "    # standard normal distribution to determine z-values\n",
    "    standard_norm = scs.norm(0, 1)\n",
    "\n",
    "    # find Z_beta from desired power\n",
    "    Z_beta = standard_norm.ppf(power)\n",
    "\n",
    "    # find Z_alpha\n",
    "    Z_alpha = standard_norm.ppf(1-sig_level/2)\n",
    "\n",
    "    # average of probabilities from both groups\n",
    "    pooled_prob = (control_rate + control_rate+rate_difference) / 2\n",
    "\n",
    "    min_N = (2 * pooled_prob * (1 - pooled_prob) * (Z_beta + Z_alpha)**2\n",
    "             / rate_difference**2)\n",
    "\n",
    "    return min_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68344278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the above function to calculate the minimum sample size\n",
    "min_sample_size(control_rate,rate_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d450867",
   "metadata": {},
   "source": [
    "Part 3: A/B testing using Machine Learning\n",
    "\n",
    "Preprocessing and Feature Engineering\n",
    "\n",
    "In this section we will\n",
    "\n",
    "take the subset of the data to be modelled\n",
    "encode categorical variables into numeric variables\n",
    "check the correlation between variables\n",
    "scale the variable\n",
    "check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b26e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice the data removing \"auction_id\" and \"no\" columns\n",
    "ml_data = answered.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1408563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder encodes categorical values into numeric. \n",
    "encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "# Encode all columns. \n",
    "ml_data['experiment']= encoder.fit_transform(ml_data['experiment'])\n",
    "ml_data['date']= encoder.fit_transform(ml_data['date'])\n",
    "ml_data['hour']= encoder.fit_transform(ml_data['hour'])\n",
    "ml_data['device_make']= encoder.fit_transform(ml_data['device_make'])\n",
    "ml_data['browser']= encoder.fit_transform(ml_data['browser'])\n",
    "ml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if we have sufficient sample size\n",
    "ml_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get correlation of the variables\n",
    "correlation = ml_data.corr()\n",
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "plt.title(\"correlation of variables\")\n",
    "sns.heatmap(correlation, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The variables are not very correlated, except for browser and device make, so we can drop either of the two. Here, we will drop device make. Let's do Spearmans test before dropping them...\n",
    "browser = ml_data.browser\n",
    "device_make = ml_data.device_make\n",
    "sp_c = spearmanr(browser, device_make)\n",
    "print(sp_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b912141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop device_make column since it is correlated with browser\n",
    "ml_data.drop(\"device_make\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c908cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "ml_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ae12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAking sure the target value is binary\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.title(\"value counts of yes column\")\n",
    "sns.countplot(x = \"yes\", data=ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5de7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nowthe variables are all numeric\n",
    "ml_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9def6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalling the variables to be between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "scaled = pd.DataFrame(scaler.fit_transform(ml_data), columns=(\"experiment\",\"date\",\"hour\",\"platform_os\",\"browser\",\"yes\"))\n",
    "scaled.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now split the data into training, validating and testing sets\n",
    "#Separate the pridictor and target variables\n",
    "X = scaled.iloc[:,:-1]\n",
    "Y = scaled.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the train_test_split twice to split the data into three groups\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
    "\n",
    "# 0.23 x 0.9 = 0.2007\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.23, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set our k-fold cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5bf81",
   "metadata": {},
   "source": [
    "since all classifiers models can use logarithmic loss function, we can define functions for all models as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the models loss and returns it\n",
    "def calculate_loss(model):\n",
    "    model = model\n",
    "    # predict probabilities\n",
    "    probs = model.predict_proba(X_val)\n",
    "    # keep the predictions for class 1 only\n",
    "    probs = probs[:, 1]\n",
    "    # calculate log loss\n",
    "    loss = log_loss(Y_val, probs)*100\n",
    "    print(\"Loss: %.2f\"%loss, \"%\")    \n",
    "\n",
    "#plots feature importance from the model \n",
    "def plot_feature_importance(importance):\n",
    "    plt.title(\"feature importance\")\n",
    "    plt.xlabel(\"features\")\n",
    "    plt.ylabel(\"importance\")\n",
    "    plt.bar(X_train.columns, importance)\n",
    "    plt.show()\n",
    "\n",
    "#returns prediction dataframe using the model\n",
    "def print_predicted(model):\n",
    "    prediction = model.predict(X_test)\n",
    "    predicted_values = pd.DataFrame({\"experiment\" : X_test.experiment,\"actual\" : Y_test,\"predicted\" : prediction})\n",
    "    return predicted_values\n",
    "\n",
    "#returns the confusion martix for the model\n",
    "def confusion_matrix(model):\n",
    "    prediction = model.predict(X_test)\n",
    "    return metrics.confusion_matrix(Y_test, prediction)\n",
    "\n",
    "#returns the mean accuracy of the k-fold iterations\n",
    "def print_accuracy(model):\n",
    "    accuracy = cross_val_score(model, X_train, Y_train, cv=k_fold, scoring= 'accuracy').mean()*100\n",
    "    print(\"Accuracy: %.2f\"%accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc20eb",
   "metadata": {},
   "source": [
    "We first use Logistic regression to model the data and see it's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use logistic regression from sklearn\n",
    "log_regression = LogisticRegression()\n",
    "#fit the training data into the model\n",
    "log_regression.fit(X_train,Y_train)\n",
    "#printing the mean accuracy of all iterations of the k-fold\n",
    "print_accuracy(log_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142397eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating loss\n",
    "calculate_loss(log_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43a1659",
   "metadata": {},
   "source": [
    "The model is performing poorly with accuracy 55% and loss 70.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting feature importance\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plot_feature_importance(log_regression.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be9d139",
   "metadata": {},
   "source": [
    "We can observe from the graph that the most important feature is platform_os. Experiment group does not seem to have a significant effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted values\n",
    "print_predicted(log_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64052a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "confusion_matrix(log_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ddff0",
   "metadata": {},
   "source": [
    "Train a Decision tree model to get a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2122d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the model from sklearn\n",
    "d_tree = DecisionTreeClassifier()\n",
    "#fit the data\n",
    "d_tree.fit(X_train,Y_train)\n",
    "#print accuracy\n",
    "print_accuracy(d_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating loss\n",
    "calculate_loss(d_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting feature importance\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plot_feature_importance(d_tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabffaa3",
   "metadata": {},
   "source": [
    "This model is not doing very good either. In contrary to the previous observation,\n",
    "platform_os has the least effect on the prediction while the date and hour appear to be most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde2199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted values\n",
    "print_predicted(d_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "confusion_matrix(d_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f33da",
   "metadata": {},
   "source": [
    "Let's use an XG Boost model and see if it can perform any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate model\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=Y_train)\n",
    "xg_boost = xgb.XGBClassifier()\n",
    "#fit the data\n",
    "xg_boost.fit(X_train,Y_train)\n",
    "#print accuracy\n",
    "print_accuracy(xg_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150dbc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate model\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=Y_train)\n",
    "xg_boost = xgb.XGBClassifier()\n",
    "#fit the data\n",
    "xg_boost.fit(X_train,Y_train)\n",
    "#print accuracy\n",
    "print_accuracy(xg_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating loss\n",
    "calculate_loss(xg_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a018b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting feature importance\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plot_feature_importance(xg_boost.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a4ae3a",
   "metadata": {},
   "source": [
    "The accuracy of this model is similar to the previous models, but it now shows that experiment group is driving \n",
    "the model along with browser type and hour of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted values\n",
    "print_predicted(xg_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1430c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "confusion_matrix(xg_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457d468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525bc9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d328742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
